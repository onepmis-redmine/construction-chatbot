from fastapi import FastAPI
from pydantic import BaseModel
import chromadb
from sentence_transformers import SentenceTransformer
import httpx
import json
from fastapi.middleware.cors import CORSMiddleware #frontend React í”„ë¡œì íŠ¸ ì¶”ê°€
import logging
import os
from dotenv import load_dotenv
load_dotenv()
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")


#ê·¸ë¡3 ë¡œê¹… ì„¤ì •
logging.basicConfig(
    filename="query_logs.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
      
# FastAPI ì•± ìƒì„±
app = FastAPI()

#frontend React í”„ë¡œì íŠ¸ ì¶”ê°€ ì‹œì‘
# CORS ì„¤ì • (React ê°œë°œ ì„œë²„ì—ì„œ ì˜¤ëŠ” ìš”ì²­ í—ˆìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000",
        "https://construction-chatbot-api.onrender.com"
        "*"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
#frontend React í”„ë¡œì íŠ¸ ì¶”ê°€ ë

# ChromaDB í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
vector_db_path = os.getenv("VECTOR_DB_PATH", "/app/api_server/vector_db")
os.makedirs(vector_db_path, exist_ok=True)  # ë””ë ‰í† ë¦¬ ìƒì„±
chroma_client = chromadb.PersistentClient(path=vector_db_path)
collection = chroma_client.get_or_create_collection(name="construction_manuals")

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¶”ê°€ (ë¹ˆ ì»¬ë ‰ì…˜ ë°©ì§€)
if collection.count() == 0:
    collection.add(
        documents=["ê±´ì„¤ì •ë³´ì‹œìŠ¤í…œì€ ê±´ì„¤ í”„ë¡œì íŠ¸ ê´€ë¦¬ë¥¼ ìœ„í•œ ì†Œí”„íŠ¸ì›¨ì–´ì…ë‹ˆë‹¤."],
        metadatas=[{"source": "manual.pdf"}],
        ids=["doc1"]
    )
    
# ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
embedder = SentenceTransformer("all-MiniLM-L6-v2", device="cpu", cache_folder=None)

# ì§ˆë¬¸ í˜•ì‹ ì •ì˜
class Question(BaseModel):
    query: str

# OpenRouter í˜¸ì¶œ í•¨ìˆ˜
def call_openrouter(prompt: str) -> str:
    headers = {
        "Authorization": OPENROUTER_API_KEY,
        "Content-Type": "application/json"
    }
    payload = {
        "model": "openai/gpt-3.5-turbo",
        "messages": [{"role": "user", "content": prompt}]
        # ,
        # "temperature": 0.2, # ë‹µë³€ì´ ë” ë³´ìˆ˜ì ì´ê³  í”„ë¡¬í”„íŠ¸ì— ì¶©ì‹¤
        # "max_tokens": 200 # ë‹µë³€ì´ ë„ˆë¬´ ê¸¸ì–´ì§€ë©´ ë¬¸ë§¥ì„ ë²—ì–´ë‚  ê°€ëŠ¥ì„±ì´ ìˆ

    }

    print("ğŸ”’ headers =", headers)
    
    response = httpx.post(
        url="https://openrouter.ai/api/v1/chat/completions",
        headers=headers,
        json=payload,
        timeout=60.0,
        verify=False  # í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œë§Œ ì‚¬ìš©
    )

    print("ğŸ” status code:", response.status_code)
    print("ğŸ“¦ response body:", response.text)

    data = response.json()
    try:
        return data["choices"][0]["message"]["content"]
    except Exception:
        return f"âŒ OpenRouter ì‘ë‹µ ì˜¤ë¥˜:\n{json.dumps(data, indent=2, ensure_ascii=False)}"

# API ì—”ë“œí¬ì¸íŠ¸
@app.post("/ask")
def ask_question(q: Question):
    query = q.query
    query_embedding = embedder.encode([query]).tolist()[0]

    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=5
    )

    # ì¶œì²˜ í¬í•¨ëœ í…ìŠ¤íŠ¸ êµ¬ì„±
    retrieved_info = ""
    sources = []  # sources ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    for doc, meta in zip(results["documents"][0], results["metadatas"][0]):
        source_info = meta.get("source", "ì•Œ ìˆ˜ ì—†ëŠ” ì¶œì²˜") if meta else "ì•Œ ìˆ˜ ì—†ëŠ” ì¶œì²˜"
        retrieved_info += f"{doc}\n[ì¶œì²˜: {source_info}]\n\n"
        sources.append(source_info)  # ì¶œì²˜ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
    

    # GPT í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""ë‹¤ìŒì€ ì‹œìŠ¤í…œ ë§¤ë‰´ì–¼ì˜ ì¼ë¶€ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µë³€í•´ ì£¼ì„¸ìš”. ë§¤ë‰´ì–¼ì—ì„œ ë‹µì„ ì°¾ì•˜ë‹¤ë©´ ë°”ë¡œ ë³´ì—¬ì£¼ì„¸ìš”.


[ì°¸ê³  ë¬¸ì„œ]
{retrieved_info}

[ì‚¬ìš©ì ì§ˆë¬¸]
{query}

[ë‹µë³€]
"""

    answer = call_openrouter(prompt)
    
    # ë¡œê¹… ì¶”ê°€: ì§ˆë¬¸, ë‹µë³€, ì¶œì²˜ ê¸°ë¡
    logging.info(f"Question: {query} | Answer: {answer} | Sources: {sources}")

    # âœ… ì½˜ì†”ì— ì¶œë ¥
    print("=== ì‚¬ìš©ì ì§ˆë¬¸ ===")
    print(query)
    print("=== GPT ì‘ë‹µ ===")
    print(answer)
    print("=== ì¶œì²˜ ===")
    print(sources)

    return {
        "answer": answer,
        "sources": sources  # ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
    }

@app.get("/health")
def health_check():
    return {"status": "ok"}