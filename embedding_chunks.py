#ì½”íŒŒì¼ëŸ¿ì´ ì¶”ì²œí•´ì¤€ ìˆ˜ì •ëœ ì½”ë“œ
import os
import json
import chromadb
from sentence_transformers import SentenceTransformer
from tqdm import tqdm
from pathlib import Path


# í´ë” ê²½ë¡œ
CHUNKS_DIR = "chunks/"
DB_DIR = "vector_db/"


# ì´ ë¶€ë¶„ ì¶”ê°€!
chunk_dir = Path("chunks")
chunk_paths = sorted(chunk_dir.glob("*.txt"))


# ğŸ›  í´ë” ì¡´ì¬ ì—¬ë¶€ í™•ì¸
if not os.path.exists(CHUNKS_DIR):
    print(f"âš ï¸ í´ë” '{CHUNKS_DIR}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    exit(1)

os.makedirs(DB_DIR, exist_ok=True)  # ë²¡í„°DB ì €ì¥í•  í´ë” ìƒì„±

# ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„±
chroma_client = chromadb.PersistentClient(path=DB_DIR)

# ë²¡í„°DB Collection ìƒì„±
collection = chroma_client.get_or_create_collection(name="construction_manuals")

# ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
embedder = SentenceTransformer('all-MiniLM-L6-v2')

# ë¬¸ë‹¨ ì½ê³  ì„ë² ë”©í•´ì„œ ì €ì¥
batch_size = 32  # âœ… ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ ìµœì í™”
total_added = 0

for filename in tqdm(os.listdir(CHUNKS_DIR)):
    if not filename.endswith(".json"):
        continue

    filepath = os.path.join(CHUNKS_DIR, filename)

    try:
        with open(filepath, "r", encoding="utf-8") as f:
            chunks = json.load(f)
    except json.JSONDecodeError:
        print(f"âŒ {filename} íŒŒì¼ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        continue

    texts = [chunk.get("text", "").strip() for chunk in chunks if chunk.get("text")]
    ids = [f"{filename}_{i}" for i in range(len(texts))]
    metadatas = [{"source": filename}] * len(texts)


    # âœ… ë¹ˆ ë¦¬ìŠ¤íŠ¸ ì˜ˆì™¸ ì²˜ë¦¬
    if not texts:
        print(f"âš ï¸ {filename}ì—ì„œ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        continue

    embeddings = []
    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i + batch_size]
        embeddings.extend(embedder.encode(batch_texts).tolist())

    if not (len(texts) == len(embeddings) == len(ids) == len(metadatas)):
        print(f"âŒ ë°ì´í„° ê¸¸ì´ ë¶ˆì¼ì¹˜: texts={len(texts)}, embeddings={len(embeddings)}, ids={len(ids)}, metadatas={len(metadatas)}")
        continue

    try:
        collection.add(
            documents=texts,
            embeddings=embeddings,
            ids=ids,
            metadatas=metadatas
        )
        total_added += len(texts)        
    except Exception as e:
        print(f"âŒ ë²¡í„°DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

print(f"âœ… ëª¨ë“  ì„ë² ë”© ì €ì¥ ì™„ë£Œ! ì´ ì¶”ê°€ëœ ë¬¸ì„œ ìˆ˜: {total_added}")